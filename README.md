
# ClearMind 

Welcome to ClearMind! This iOS app functios to transcribe user speech in real-time both in the app and in the background and then store it in a mutable GraphQL DynamoDB database using Amazon Web Services's App Sync that allows for both online and offline usage. 

Because this app works heavily with an Amazon Web Services back-end, a lot of programming was done via the command-line interface and Amazon Web Services website which can not be shown here. In addition, if access to my Amazon Web Services account is required to run this app in full for some reason, and your name is Eric Lin, text me at 2242160676 a.s.a.p. so that I can give you the login information. 


## Getting Started

### Pre-requisites

This app was made on XCode 11.2.1 for iOS 13.2 Deployment Target on an iPhone 11 Xs Max. 

### Installing

1) Download the files submitted through the cs50 IDE [OR] clone the Github repository at http://www.github.com/ashernoel/ClearMind 
2) Use the command line to change directories into the root folder of the project and type "open ClearMind.xcworkspace" to open the project. If using a GUI, be sure to open the .xcworkspace version of the program. 
3) Use CMD+B and CMD+R to build and run the file respectivily. This app was developed for an iPhone 11 Xs Max, so this simulator will likely work the best. 

## Understand the Directory

#### Non-editable files in root directory
Do Not Edit: 
- API.swift: This file, automatically generated by AWS, contains the swift functions that mutate the GraphQL database with DynamoDB tables. 
- awsconfiguration.json: This connects basic functionality of AWS to the app. 
- amplifyconfiguration.json: This connects AWS Amplify functionality, such as analytics, to the app. 
- GenderSoundClassification.mlmodel: This is a Core ML machine learning model trained on 32 audio files to classify speech in real time as either male or female. Published online at github.com/anupamchuh/iowncode. 
- /images/ contains the images for the screenshots
- The Watch App and Watch App extension were not used in making this app.
- The ClearMindUI and ClearMindUITests folders were not used in making this app. 

#### ClearMind directory within XCode: 
Do Not Edit: 
- The first 7 files (AmplifyModels.swift, Recording.swift, Recording+Schema.swift, Todo.swift, Todo+schema.swift, User.swift, User+Schema.swift) are required for GraphQL but were computer generated and not neccesary to inderact with. 

Editable Swift Files: 
- AppDelegate.swift: This is the master swift file that tells the device what to do upon start up.
- SceneDelegate.swift: This computer generated file does not do much.
- RecordViewController.swift: This file is for the "Record" tab within the app that 1) transcribes audio and saves it using GraphQL and 2) classifies the user's speech in real-time as either male or female. Some of the code for the real-time classificaition is from github.com/anupamchuh/iowncode.
- HistoryViewController.swift: This is for the second "History" tab within the app. It shows the past recordings in a tableview that allows for 1) searching of past recordings by keywords and 2) edits of past recordings by tapping on the table view cells. 
- ProfileViewController.swift: This is for the third and final "Profile" tab within the app that presents the user with the option to logout, edit settings, or view the project on Github. 
- SettingsViewController.swift: This is for the settings view controller that allows the user to turn of notificaitons. 
- ViewController.swift: This is the initial view controller that loads upon launch and presents the user with the log-in screen. 

Other Resources:
- Main.Storyboard: This hosts a GUI for the parts of the project made using a storyboard. 
- LaunchScreen.storyboard: This computer generated storyboard starts with the app.
- Assets.xcassets: This folder contains all of the images used in this app. I made the logo in Adobe Illustrator. The iOS Glyphs were free on icons8.com. The other images are liscensed Adobe Stock. As such, all photos are legally reproducible. 
- Info.plist: This file has the app configuration that allows for background audio recording. 

## Using the App 

Upon launching the app, the user will be presented with a login screen. This is secured using AWS Cognito User Pools and allows for Facebook sign in as well. The user should login with their facebook, make a new account, or use my sample account with username ashernoel and password ashernoel. 

The app will then redirect the user to the record page. The "play button" in the middle is clickable and will start a recording. If the user talks during this recording, the voice will be transcribed without punctuation. At the same time, a separate model will predict the chance that the speaker was male or female. This recording can operate in the background if the user presses the home button. When the user stops the recording, the app will send the transcribed text of the recording via GraphQL to a DynamoDB table in the cloud. 

In the History tab, the user is presented with all of their past recordings. These recordings are 1) editable, 2) searchable, and 3) deletable. The user edits a recording by clicking on it, typing as they please, and then clicking the "Save" button above the keyboard. This will update the DynamoDB table in the cloud. In addition, the user searches the recordings by typing in the search bar. This will return all of the recordings with contents that contain the queried substring. To delete recordings, the user swipes left on a recording. This will bring up the option to delete the recording. 

The "Profile" tab lets the user log out, change push notification settings by seguing to a settings view controller, and view the code on Github. It's main function is to logout, but it has a great UI as an unecessary plus. 

If a user runs into any problems running the app, feel free to email me at ashernoel@college.harvard.edu or call or text me at 224-216-0676 with questions or bugs. 

[NOTE]: Although the app has AWS Cognito User Pools, all recordings are stored in the same DynamoDB table, which means that multiple users can access the same batch of recordings across multiple devices. This is a cool way of playing with the cloud instead of locally stored databases. 
[NOTE]: There is a 0.5 second delay between the end of the recording and when the data gets sent to Amazon, but still sometimes the transcription will update for a second time a few seconds after the audio has stopped and sent the data to DynamoDB. This is because AWS is faster than the speech-to-text transcription model. 
[NOTE]: When I run this program using the Legacy Build System on my iPhone, I get 47 warning messages, 45 of which are from AWS Cocoa Pods. When I run it on an iPhone 11, I get 48 warning messages, 45 of which are from AWS Cocoa Pods. 
[NOTE]: A known bug occurs when the record button is clicked too quickly or when nothing is said; in these cases, it is best to close out of the app and open it again.  
[NOTE]: When editing a recording on a simulator and not an iPhone, there is no "Save" button because there is no keyboard, so recordings may not be editable. 

## Screenshots

To learn more about the design of the app, view the DESIGN.md document in the same directory as README.md

<p align="center">

<img src="/images/login.png" alt="Default Login Screen" width="300"/><img src="/images/record.png" alt="Default Login Screen" width="300"/>

<img src="/images/history.png" alt="Default Login Screen" width="300"/><img src="/images/profile.png" alt="Default Login Screen" width="300"/>

<img src="/images/edit.png" alt="Default Login Screen" width="300"/><img src="/images/search.png" alt="Default Login Screen" width="300"/>


</p>

## Built With

* [XCode]
* [Amazon Web Services]


